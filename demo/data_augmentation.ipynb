{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 数据增强"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本教程将介绍数据增强的使用方法，使用的文件是Unet/data_keras.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先导入data_Keras里面的Augmentation和DataProcess模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from Unet.data_Keras import Augmentation, DataProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来做数据增强,首先将image和label合并到一个图片中，然后对每一个图片做数据增强augmentation()，保存到了../data_set/aug_merge/-/-中。再用split_merge()函数将增强的合成图片分开成image和label，分别保存到../data_set/aug_train/-/-和../data_set/aug_label/-/-中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行 Augmentation\n",
      "30 30\n",
      "running 0 doAugmenttaion\n",
      "running 1 doAugmenttaion\n",
      "running 2 doAugmenttaion\n",
      "running 3 doAugmenttaion\n",
      "running 4 doAugmenttaion\n",
      "running 5 doAugmenttaion\n",
      "running 6 doAugmenttaion\n",
      "running 7 doAugmenttaion\n",
      "running 8 doAugmenttaion\n",
      "running 9 doAugmenttaion\n",
      "running 10 doAugmenttaion\n",
      "running 11 doAugmenttaion\n",
      "running 12 doAugmenttaion\n",
      "running 13 doAugmenttaion\n",
      "running 14 doAugmenttaion\n",
      "running 15 doAugmenttaion\n",
      "running 16 doAugmenttaion\n",
      "running 17 doAugmenttaion\n",
      "running 18 doAugmenttaion\n",
      "running 19 doAugmenttaion\n",
      "running 20 doAugmenttaion\n",
      "running 21 doAugmenttaion\n",
      "running 22 doAugmenttaion\n",
      "running 23 doAugmenttaion\n",
      "running 24 doAugmenttaion\n",
      "running 25 doAugmenttaion\n",
      "running 26 doAugmenttaion\n",
      "running 27 doAugmenttaion\n",
      "running 28 doAugmenttaion\n",
      "running 29 doAugmenttaion\n",
      "running splitMerge\n",
      "../data_set/aug_merge/0\n",
      "../data_set/aug_merge/1\n",
      "../data_set/aug_merge/2\n",
      "../data_set/aug_merge/3\n",
      "../data_set/aug_merge/4\n",
      "../data_set/aug_merge/5\n",
      "../data_set/aug_merge/6\n",
      "../data_set/aug_merge/7\n",
      "../data_set/aug_merge/8\n",
      "../data_set/aug_merge/9\n",
      "../data_set/aug_merge/10\n",
      "../data_set/aug_merge/11\n",
      "../data_set/aug_merge/12\n",
      "../data_set/aug_merge/13\n",
      "../data_set/aug_merge/14\n",
      "../data_set/aug_merge/15\n",
      "../data_set/aug_merge/16\n",
      "../data_set/aug_merge/17\n",
      "../data_set/aug_merge/18\n",
      "../data_set/aug_merge/19\n",
      "../data_set/aug_merge/20\n",
      "../data_set/aug_merge/21\n",
      "../data_set/aug_merge/22\n",
      "../data_set/aug_merge/23\n",
      "../data_set/aug_merge/24\n",
      "../data_set/aug_merge/25\n",
      "../data_set/aug_merge/26\n",
      "../data_set/aug_merge/27\n",
      "../data_set/aug_merge/28\n",
      "../data_set/aug_merge/29\n"
     ]
    }
   ],
   "source": [
    "aug = Augmentation()\n",
    "aug.augmentation()\n",
    "aug.split_merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后就可以制作各个数据集了。这里做了小规模的训练集、验证集和测试集， 图片大小采用的是512×512，用的是tfrecord格式，建议大家以后也这样做，方便存储和分享，而且读取数据也会快很多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 11626 files\n",
      "Done train_set writing 0.00%\n",
      "Done train_set writing 4.76%\n",
      "Done train_set writing 9.52%\n",
      "Done train_set writing 14.29%\n",
      "Done train_set writing 19.05%\n",
      "Done train_set writing 23.81%\n",
      "Done train_set writing 28.57%\n",
      "Done train_set writing 33.33%\n",
      "Done train_set writing 38.10%\n",
      "Done train_set writing 42.86%\n",
      "Done train_set writing 47.62%\n",
      "Done train_set writing 52.38%\n",
      "Done train_set writing 57.14%\n",
      "Done train_set writing 61.90%\n",
      "Done train_set writing 66.67%\n",
      "Done train_set writing 71.43%\n",
      "Done train_set writing 76.19%\n",
      "Done train_set writing 80.95%\n",
      "Done train_set writing 85.71%\n",
      "Done train_set writing 90.48%\n",
      "Done train_set writing 95.24%\n",
      "Done whole train_set writing\n",
      "Done validation_set writing 0.00%\n",
      "Done validation_set writing 37.04%\n",
      "Done validation_set writing 74.07%\n",
      "Done whole validation_set writing\n",
      "Done test_set writing 0.00%\n",
      "Done test_set writing 33.33%\n",
      "Done test_set writing 66.67%\n",
      "Done test_set writing\n"
     ]
    }
   ],
   "source": [
    "mydata = DataProcess(512, 512)\n",
    "mydata.write_img_to_tfrecords()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到此，数据增强和数据集就做好了，可以进行训练了"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}